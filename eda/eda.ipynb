{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"../data/raw/MWI_2010_individual.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Drop very sparse columns (>90% missing)\n",
    "# -------------------------------\n",
    "drop_cols = [\n",
    "    \"ind_health2\",\n",
    "    \"ind_health4\",\n",
    "    \"ind_health6\",\n",
    "    \"ind_health7\",\n",
    "    \"ind_health8\",\n",
    "    \"ind_birthplace\",\n",
    "    \"ind_birthattend\",\n",
    "    \"ind_work5\",\n",
    "]\n",
    "\n",
    "# optional: drop ind_language if you consider too sparse\n",
    "drop_cols.append(\"ind_language\")\n",
    "\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Impute / encode categorical missing values\n",
    "# -------------------------------\n",
    "# columns where missing means \"unknown\"\n",
    "unknown_cols = [\n",
    "    \"ind_educfath\",\n",
    "    \"ind_educmoth\",\n",
    "    \"ind_religion\",\n",
    "    \"ind_marital\",\n",
    "    \"ind_rwchichewa\",\n",
    "    \"ind_rwenglish\",\n",
    "    \"ind_educ01\",\n",
    "    \"ind_breakfast\",\n",
    "    \"ind_work1\",\n",
    "    \"ind_work2\",\n",
    "    \"ind_work6\",\n",
    "]\n",
    "\n",
    "for col in unknown_cols:\n",
    "    df[col] = df[col].fillna(\"unknown\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Education conditional columns → \"not_applicable\"\n",
    "# -------------------------------\n",
    "educ_conditional = [\n",
    "    \"ind_educ02\",\n",
    "    \"ind_educ03\",\n",
    "    \"ind_educ04\",\n",
    "    \"ind_educ05\",\n",
    "    \"ind_educ06\",\n",
    "    \"ind_educ07\",\n",
    "    \"ind_educ08\",\n",
    "    \"ind_educ09\",\n",
    "    \"ind_educ10\",\n",
    "    \"ind_educ11\",\n",
    "    \"ind_educ12\",\n",
    "]\n",
    "for col in educ_conditional:\n",
    "    df[col] = df[col].fillna(\"not_applicable\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Health variables with smaller missingness\n",
    "# -------------------------------\n",
    "health_cols = [\"ind_health1\", \"ind_health3\", \"ind_health5\"]\n",
    "for col in health_cols:\n",
    "    df[col] = df[col].fillna(\"no_response\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Work variable with high NA but keep\n",
    "# -------------------------------\n",
    "df[\"ind_work3\"] = df[\"ind_work3\"].fillna(\"not_applicable\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Convert to categorical where appropriate\n",
    "# -------------------------------\n",
    "categorical_cols = [col for col in df.columns if col not in [\"ind_age\", \"wta_hh\"]]\n",
    "df[categorical_cols] = df[categorical_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------- Load raw ----------\n",
    "raw_path = \"../data/raw/MWI_2010_individual.dta\"\n",
    "df_raw = pd.read_stata(raw_path, convert_categoricals=False)\n",
    "\n",
    "# ---------- Missingness summary BEFORE ----------\n",
    "missing_counts = df_raw.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nMissing values BEFORE cleaning (top 30):\")\n",
    "print(missing_counts.head(30))\n",
    "\n",
    "# ---------- Missingness heatmap (BEFORE) ----------\n",
    "# To keep the plot readable/fast, sample rows if very large\n",
    "sample_n = min(5000, len(df_raw))\n",
    "df_samp = df_raw.sample(sample_n, random_state=42)\n",
    "\n",
    "# Build a boolean matrix (1 = missing, 0 = present), order columns by % missing\n",
    "miss_mat = df_samp.isnull().astype(int)\n",
    "col_order = miss_mat.mean().sort_values(ascending=False).index\n",
    "miss_mat = miss_mat[col_order].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(miss_mat, aspect=\"auto\", interpolation=\"nearest\")\n",
    "plt.title(f\"Missingness Heatmap (before cleaning) — {sample_n} sampled rows\")\n",
    "plt.xlabel(\"Columns (sorted by % missing)\")\n",
    "plt.ylabel(\"Rows (sample)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- CLEANING RULES ----------\n",
    "# 1) Drop very sparse columns (>~90% missing or per earlier decision)\n",
    "drop_cols = [\n",
    "    \"ind_health2\",\n",
    "    \"ind_health4\",\n",
    "    \"ind_health6\",\n",
    "    \"ind_health7\",\n",
    "    \"ind_health8\",\n",
    "    \"ind_birthplace\",\n",
    "    \"ind_birthattend\",\n",
    "    \"ind_work5\",\n",
    "    \"ind_language\",  # optional drop (high missingness); remove if you prefer to keep\n",
    "]\n",
    "df = df_raw.drop(columns=[c for c in drop_cols if c in df_raw.columns])\n",
    "\n",
    "# 2) Impute \"unknown\"\n",
    "unknown_cols = [\n",
    "    \"ind_educfath\",\n",
    "    \"ind_educmoth\",\n",
    "    \"ind_religion\",\n",
    "    \"ind_marital\",\n",
    "    \"ind_rwchichewa\",\n",
    "    \"ind_rwenglish\",\n",
    "    \"ind_educ01\",\n",
    "    \"ind_breakfast\",\n",
    "    \"ind_work1\",\n",
    "    \"ind_work2\",\n",
    "    \"ind_work6\",\n",
    "]\n",
    "for col in unknown_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"unknown\")\n",
    "\n",
    "# 3) Education conditional → \"not_applicable\"\n",
    "educ_conditional = [\n",
    "    \"ind_educ02\",\n",
    "    \"ind_educ03\",\n",
    "    \"ind_educ04\",\n",
    "    \"ind_educ05\",\n",
    "    \"ind_educ06\",\n",
    "    \"ind_educ07\",\n",
    "    \"ind_educ08\",\n",
    "    \"ind_educ09\",\n",
    "    \"ind_educ10\",\n",
    "    \"ind_educ11\",\n",
    "    \"ind_educ12\",\n",
    "]\n",
    "for col in educ_conditional:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"not_applicable\")\n",
    "\n",
    "# 4) Health with smaller missingness → \"no_response\"\n",
    "for col in [\"ind_health1\", \"ind_health3\", \"ind_health5\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"no_response\")\n",
    "\n",
    "# 5) Work var w/ high NA but keep → \"not_applicable\"\n",
    "if \"ind_work3\" in df.columns:\n",
    "    df[\"ind_work3\"] = df[\"ind_work3\"].fillna(\"not_applicable\")\n",
    "\n",
    "# 6) Dtypes\n",
    "numeric_keep = [\"ind_age\", \"wta_hh\"]\n",
    "categorical_cols = [c for c in df.columns if c not in numeric_keep]\n",
    "df[categorical_cols] = df[categorical_cols].astype(\"category\")\n",
    "\n",
    "# ---------- EDA AFTER ----------\n",
    "print(\"\\nMissing values AFTER cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Distribution plots for imputed columns\n",
    "for col in [\n",
    "    *unknown_cols,\n",
    "    *educ_conditional,\n",
    "    \"ind_work3\",\n",
    "    \"ind_health1\",\n",
    "    \"ind_health3\",\n",
    "    \"ind_health5\",\n",
    "]:\n",
    "    if col in df.columns:\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        df[col].value_counts(dropna=False).plot(kind=\"bar\")\n",
    "        plt.title(f\"Distribution after imputation: {col}\")\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced dataset\n",
    "\n",
    "df.poor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Helper: build preprocessor\n",
    "# ------------------------------\n",
    "def build_preprocessor(X, model_type=\"tree\", numeric_features=(\"ind_age\", \"wta_hh\")):\n",
    "    \"\"\"\n",
    "    Ensures categorical columns are coerced to string before encoding to avoid\n",
    "    mixed-type errors like 'Encoders require uniformly strings or numbers'.\n",
    "    model_type in {'tree','linear','knn','svm'}.\n",
    "    \"\"\"\n",
    "    numeric_features = list(numeric_features)\n",
    "    categorical_features = [c for c in X.columns if c not in numeric_features]\n",
    "\n",
    "    # Step to coerce categorical block to string\n",
    "    to_str = FunctionTransformer(lambda A: A.astype(str), feature_names_out=\"one-to-one\")\n",
    "\n",
    "    if model_type in [\"linear\", \"knn\", \"svm\"]:\n",
    "        cat_pipe = Pipeline(\n",
    "            [\n",
    "                (\"to_str\", to_str),\n",
    "                (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "            ]\n",
    "        )\n",
    "        num_pipe = StandardScaler()  # scale numeric for these models\n",
    "        return ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", num_pipe, numeric_features),\n",
    "                (\"cat\", cat_pipe, categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "        )\n",
    "\n",
    "    elif model_type == \"tree\":\n",
    "        # Trees don’t need scaling; OrdinalEncoder gives compact features\n",
    "        cat_pipe = Pipeline(\n",
    "            [\n",
    "                (\"to_str\", to_str),\n",
    "                (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "            ]\n",
    "        )\n",
    "        return ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", \"passthrough\", numeric_features),\n",
    "                (\"cat\", cat_pipe, categorical_features),\n",
    "            ],\n",
    "            remainder=\"drop\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'tree', 'linear', 'knn', or 'svm'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# New imports\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ------------------------------\n",
    "# Target & features\n",
    "# ------------------------------\n",
    "y = df[\"poor\"]\n",
    "X = df.drop(columns=[\"poor\"])\n",
    "\n",
    "# ------------------------------\n",
    "# Split\n",
    "# ------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Models (no SVM)\n",
    "# ------------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), \"linear\"),\n",
    "    \"Random Forest\": (RandomForestClassifier(n_estimators=200, random_state=42), \"tree\"),\n",
    "    \"KNN\": (KNeighborsClassifier(n_neighbors=5), \"knn\"),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "        \"tree\",\n",
    "    ),\n",
    "    \"LightGBM\": (LGBMClassifier(random_state=42), \"tree\"),\n",
    "}\n",
    "\n",
    "# ------------------------------\n",
    "# Train + Evaluate\n",
    "# ------------------------------\n",
    "for name, (model, model_type) in models.items():\n",
    "    print(f\"\\n🔹 Training {name}...\")\n",
    "    preproc = build_preprocessor(X, model_type=model_type)\n",
    "    pipe = Pipeline([(\"preprocess\", preproc), (\"model\", model)])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    print(f\"✅ {name} Results\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification-poverty-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
