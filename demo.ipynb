{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691d93f2",
   "metadata": {},
   "source": [
    "\n",
    "# Poverty Classifier System Demo \n",
    "\n",
    "Learning Team 1 (MSDS 2025 PT-B): \n",
    "- Asiado, Jian \n",
    "- Dorado, Joshua\n",
    "- Fajardo, Jethro\n",
    "\n",
    "### **About**\n",
    "\n",
    "This notebook demonstrates how to interact with **Poverty Classifier** and provides documentations of the major components endâ€‘toâ€‘end.\n",
    "\n",
    "This classifier was trained on Malawi Integrated Household Living Conditions Survey (IHS) 2010â€“2011 by the Malawi National Statistical Office (NSO). \n",
    "\n",
    "Source: https://microdata.worldbank.org/index.php/catalog/3016/study-description\n",
    "\n",
    "**Components overview**\n",
    "- **Airflow** orchestrates five main pipelines \n",
    "1. Data Download and Extraction\n",
    "2. Data Preprocessing\n",
    "3. Training \n",
    "4. Model Evaluation \n",
    "5. Drift Detection \n",
    "\n",
    "- **MLflow** tracks experiments (params, metrics, artifacts) and manages the **Model Registry**.\n",
    "In the experimentation tracking, there are five ML models that are tested simultaneously: \n",
    "    - KNN\n",
    "    - Logistic Regression\n",
    "    - Random Forest\n",
    "    - XGBoost\n",
    "\n",
    "- **FastAPI** exposes the **`/predict`** and **`/model`** endpoints for online inference and model introspection.\n",
    "- **Evidently AI** generates **data/drift** and **performance monitoring** reports; reports are logged to **MLflow artifacts**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d542348",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup Instructions\n",
    "\n",
    "> Run everything with Docker. Adjust ports as needed in your `docker-compose.yml`.\n",
    "\n",
    "**Start the stack**\n",
    "```bash\n",
    "docker compose up build\n",
    "```\n",
    "\n",
    "For next runs, \n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "**Default URLs**\n",
    "- Airflow UI: <http://localhost:8080>\n",
    "- MLflow UI: <http://localhost:5000>\n",
    "- FastAPI service (inference): <http://localhost:8000>\n",
    "- (Optional) Evidently Monitoring UI (if used): <http://localhost:8501>\n",
    "\n",
    "> Tip: Confirm services are healthy before running the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcd1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Optional) If running outside Docker, ensure these are installed.\n",
    "# !pip install requests mlflow pandas ipython\n",
    "# Evidently is only needed if you plan to generate reports locally:\n",
    "# !pip install evidently\n",
    "\n",
    "print(\"Environment ready. If you're running in Docker, dependencies should already be baked in.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509817c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Configuration\n",
    "\n",
    "The following are the list of base URLs for all services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986016ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# ---- Inference / API ----\n",
    "FASTAPI_BASE = os.getenv(\"FASTAPI_BASE\", \"http://localhost:8000\")\n",
    "\n",
    "# ---- MLflow ----\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "MLFLOW_EXPERIMENT_NAME = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"Default\")\n",
    "MLFLOW_MODEL_NAME = os.getenv(\"MLFLOW_MODEL_NAME\", \"my_model\")  # name in Model Registry\n",
    "MLFLOW_DRIFT_REPORT_PATH = os.getenv(\"MLFLOW_DRIFT_REPORT_PATH\", \"reports/drift_report.html\")  # relative artifact path\n",
    "\n",
    "FASTAPI_PREDICT_URL = f\"{FASTAPI_BASE}/predict\"\n",
    "FASTAPI_MODEL_URL = f\"{FASTAPI_BASE}/model\"\n",
    "\n",
    "print(\"FASTAPI_PREDICT_URL:\", FASTAPI_PREDICT_URL)\n",
    "print(\"FASTAPI_MODEL_URL  :\", FASTAPI_MODEL_URL)\n",
    "print(\"MLFLOW_TRACKING_URI:\", MLFLOW_TRACKING_URI)\n",
    "print(\"Experiment name     :\", MLFLOW_EXPERIMENT_NAME)\n",
    "print(\"Registry model name :\", MLFLOW_MODEL_NAME)\n",
    "print(\"Drift report relpath:\", MLFLOW_DRIFT_REPORT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8fc13",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Prediction Request\n",
    "\n",
    "Simulate a client making a **POST** request to the `/predict` endpoint.\n",
    "- Replace `sample_payload` with your model's expected schema.\n",
    "- The server should respond with a JSON payload containing prediction.\n",
    "    - 1 if poor\n",
    "    - 0 if not poor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Example payload â€” adjust fields to match your FastAPI schema\n",
    "sample_payload = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "        \"hid\": \"101010160009\",\n",
    "        \"iid\": 1,\n",
    "        \"ind_sex\": 2,\n",
    "        \"ind_relation\": 1,\n",
    "        \"ind_age\": 31,\n",
    "        \"ind_educfath\": 2.0,\n",
    "        \"ind_educmoth\": 1.0,\n",
    "        \"ind_language\": 11.0,\n",
    "        \"ind_religion\": 3.0,\n",
    "        \"ind_marital\": 1.0,\n",
    "        \"ind_readwrite\": 1,\n",
    "        \"ind_rwchichewa\": 1.0,\n",
    "        \"ind_rwenglish\": 1.0,\n",
    "        \"ind_educ01\": 1.0,\n",
    "        \"ind_educ02\": 0,\n",
    "        \"ind_educ03\": 8.0,\n",
    "        \"ind_educ04\": 2.0,\n",
    "        \"ind_educ05\": 0.0,\n",
    "        \"ind_educ06\": 0,\n",
    "        \"ind_educ07\": 0.0,\n",
    "        \"ind_educ08\": 2.0,\n",
    "        \"ind_educ09\": 0,\n",
    "        \"ind_educ10\": 0,\n",
    "        \"ind_educ11\": 0,\n",
    "        \"ind_educ12\": 0,\n",
    "        \"ind_health1\": 0.0,\n",
    "        \"ind_health2\": 0,\n",
    "        \"ind_health3\": 0.0,\n",
    "        \"ind_health4\": 0,\n",
    "        \"ind_health5\": 0.0,\n",
    "        \"ind_health6\": 0,\n",
    "        \"ind_health7\": 0,\n",
    "        \"ind_health8\": 0,\n",
    "        \"ind_breakfast\": 0,\n",
    "        \"ind_birthplace\": 1.0,\n",
    "        \"ind_birthattend\": 2.0,\n",
    "        \"ind_work1\": 0.0,\n",
    "        \"ind_work2\": 1.0,\n",
    "        \"ind_work3\": 0,\n",
    "        \"ind_work4\": 0,\n",
    "        \"ind_work5\": 0,\n",
    "        \"ind_work6\": 0.0,\n",
    "        \"wta_hh\": 126.56\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    resp = requests.post(FASTAPI_PREDICT_URL, json=sample_payload, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    print(\"Status:\", resp.status_code)\n",
    "    print(\"Response JSON:\")\n",
    "    print(json.dumps(resp.json(), indent=2))\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"\\n[Prediction request failed]\")\n",
    "    print(\"Make sure the FastAPI service is running and the endpoint schema matches the payload.\")\n",
    "    print(\"Error:\", e)\n",
    "    print(\"Troubleshooting: check Docker logs, ports, and your service health.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c8308b",
   "metadata": {},
   "source": [
    "### ðŸ”¹  Response (from `/predict`)\n",
    "\n",
    "The API returns predictions in the following JSON format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"predictions\": [\n",
    "    {\n",
    "      \"hid\": \"101010160009\",\n",
    "      \"label\": 1\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8c105",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Model Information Retrieval\n",
    "\n",
    "This cell calls the `/model` endpoint to fetch details like:\n",
    "- **model name/version**\n",
    "- **hyperparameters**\n",
    "- **training metadata** (e.g., run ID, timestamp)\n",
    "\n",
    "Use the response to document what the production model is and how it was trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    resp = requests.get(FASTAPI_MODEL_URL, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    print(\"Status:\", resp.status_code)\n",
    "    model_info = resp.json()\n",
    "    print(json.dumps(model_info, indent=2))\n",
    "    # Example: Explain a field if present\n",
    "    if isinstance(model_info, dict) and \"hyperparameters\" in model_info:\n",
    "        hp = model_info.get(\"hyperparameters\", {})\n",
    "        if \"max_depth\" in hp:\n",
    "            print(\"\\nExplanation: 'max_depth' controls the maximum depth of each decision tree.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"\\n[Model info request failed]\")\n",
    "    print(\"Ensure FastAPI is reachable and the /model endpoint is implemented.\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d89ff6",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Drift Detection Demonstration\n",
    "\n",
    "In this section, we fetch the **Evidently AI drift report** logged as an artifact in MLflow and render it inline.\n",
    "- We search the latest successful run (or the latest model in the **Model Registry**) and attempt to download `reports/drift_report.html`.\n",
    "- If not found, we display guidance to generate/log a report in your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "from IPython.display import IFrame, display, HTML\n",
    "import os\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "def _find_latest_run_id_from_experiment(experiment_name: str):\n",
    "    exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if exp is None:\n",
    "        return None\n",
    "    runs = mlflow.search_runs(experiment_ids=[exp.experiment_id], order_by=[\"start_time DESC\"], max_results=50)\n",
    "    if runs is None or runs.empty:\n",
    "        return None\n",
    "    # Return the most recent finished run\n",
    "    for _, row in runs.iterrows():\n",
    "        if row.get(\"status\", \"FINISHED\") in (\"FINISHED\", \"SCHEDULED\", \"RUNNING\"):\n",
    "            return row[\"run_id\"]\n",
    "    return runs.iloc[0][\"run_id\"]\n",
    "\n",
    "def _find_latest_run_id_from_registry(model_name: str):\n",
    "    try:\n",
    "        client = mlflow.tracking.MlflowClient()\n",
    "        # Prefer Production, then Staging, else most recent version\n",
    "        for stage in [\"Production\", \"Staging\"]:\n",
    "            versions = client.get_latest_versions(model_name, stages=[stage])\n",
    "            if versions:\n",
    "                return versions[0].run_id\n",
    "        # Fallback: most recent version by last_updated_timestamp\n",
    "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        if versions:\n",
    "            latest = sorted(versions, key=lambda v: v.last_updated_timestamp, reverse=True)[0]\n",
    "            return latest.run_id\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "run_id = _find_latest_run_id_from_registry(MLFLOW_MODEL_NAME) or _find_latest_run_id_from_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "if run_id is None:\n",
    "    display(HTML(\"<b>No MLflow run found.</b> Make sure experiments are logged and the Model Registry has versions.\"))\n",
    "else:\n",
    "    print(\"Using MLflow run_id:\", run_id)\n",
    "    # Try to download the drift report artifact\n",
    "    try:\n",
    "        local_path = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=MLFLOW_DRIFT_REPORT_PATH)\n",
    "        if os.path.exists(local_path):\n",
    "            print(\"Drift report downloaded to:\", local_path)\n",
    "            # Render in an iframe\n",
    "            display(IFrame(src=local_path, width=\"100%\", height=600))\n",
    "        else:\n",
    "            display(HTML(f\"<b>Artifact not found:</b> {MLFLOW_DRIFT_REPORT_PATH}. Check your pipeline artifact paths.\"))\n",
    "    except Exception as e:\n",
    "        display(HTML(f\"<b>Failed to download artifacts:</b> {e}. Confirm MLflow URI, run permissions, and artifact path.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69436456",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Interpreting the Drift Report \n",
    "\n",
    "Proposed Summary of Findings:\n",
    "\n",
    "- **Data drift**: e.g., 4/20 features show significant drift (KS-test p < 0.05).\n",
    "- **Prediction drift**: Production prediction distribution shifted right vs. training.\n",
    "- **Target drift**  If accuracy decreased from 0.88 â†’ 0.81 week-over-week.\n",
    "- **Next steps**: Retrain with recent data; re-check calibration; update data validation rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f951d",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Reproducibility Notes\n",
    "\n",
    "- This notebook is designed to **Run All** from a clean kernel.\n",
    "- If you changed configuration (ports, model name, or experiment), update the **Configuration** cell and **restart & run all**.\n",
    "- Version pinning (example): keep `mlflow`, `fastapi`, `evidently`, and model framework versions aligned with your Docker images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b931c",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Troubleshooting\n",
    "\n",
    "- **Connection errors**: Verify containers are healthy (`docker compose ps`) and ports arenâ€™t blocked.\n",
    "- **404/422 from `/predict`**: Ensure your request schema matches the FastAPI model input.\n",
    "- **MLflow artifacts missing**: Confirm your training pipeline logs the Evidently HTML report (e.g., `reports/drift_report.html`).  \n",
    "- **Authentication**: If your MLflow server requires auth, set the appropriate env vars/tokens.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
